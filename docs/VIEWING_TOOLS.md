# Parquet æ•°æ®æŸ¥çœ‹å·¥å…·æŒ‡å—

æœ¬é¡¹ç›®çš„æ•°æ®å­˜å‚¨åœ¨ Parquet æ ¼å¼ä¸­ï¼Œæœ‰å¤šç§å·¥å…·å¯ä»¥æ–¹ä¾¿åœ°æŸ¥çœ‹å’Œåˆ†æè¿™äº›æ•°æ®ã€‚

## ğŸ¯ æ¨èå·¥å…·

### 1. **DBeaver** â­ å¼ºçƒˆæ¨è
**æœ€ä½³é€‰æ‹© - åŠŸèƒ½å¼ºå¤§çš„å…è´¹æ•°æ®åº“å®¢æˆ·ç«¯**

- **ä¸‹è½½**: https://dbeaver.io/download/
- **æ”¯æŒ**: Windows, macOS, Linux
- **ç‰¹ç‚¹**: 
  - âœ… å…è´¹å¼€æº
  - âœ… å¯è§†åŒ–æŸ¥è¯¢ç•Œé¢
  - âœ… æ”¯æŒ SQL æŸ¥è¯¢
  - âœ… æ•°æ®å¯¼å‡º
  - âœ… æ•°æ®é€è§†è¡¨

**ä½¿ç”¨æ­¥éª¤**:
1. ä¸‹è½½å®‰è£… DBeaver Community Edition
2. æ–°å»ºè¿æ¥ â†’ é€‰æ‹© "DuckDB"
3. åˆ›å»ºå†…å­˜æ•°æ®åº“ï¼ˆ`:memory:`ï¼‰
4. åœ¨ SQL ç¼–è¾‘å™¨ä¸­æŸ¥è¯¢ï¼š
```sql
SELECT * FROM read_parquet('C:/Users/14737/OneDrive/06AKshare/ashare-quant/data/parquet/ashare_daily/**/*.parquet')
LIMIT 100;
```

### 2. **VS Code æ‰©å±•** ğŸ“
**æœ€æ–¹ä¾¿ - å¦‚æœä½ å·²ç»åœ¨ç”¨ VS Code**

#### a) Parquet Viewer
- **å®‰è£…**: æœç´¢ "Parquet Viewer" æˆ– "Parquet Explorer"
- **ä½¿ç”¨**: ç›´æ¥å³é”®ç‚¹å‡» `.parquet` æ–‡ä»¶ â†’ "Open with Parquet Viewer"

#### b) Rainbow CSV + DuckDB
- **å®‰è£…**: 
  - Rainbow CSV
  - DuckDB SQL Tools
- **ä½¿ç”¨**: å¯ä»¥åœ¨ VS Code ä¸­ç›´æ¥ç”¨ SQL æŸ¥è¯¢

### 3. **åœ¨çº¿å·¥å…·** ğŸŒ
**æœ€å¿«é€Ÿ - æ— éœ€å®‰è£…**

#### Parquet Viewer Online
- **ç½‘å€**: https://parquet-viewer-online.com/
- **ä½¿ç”¨**: ä¸Šä¼  Parquet æ–‡ä»¶ç›´æ¥æŸ¥çœ‹
- **é™åˆ¶**: æ–‡ä»¶å¤§å°é™åˆ¶ï¼ˆé€šå¸¸ < 100MBï¼‰

âš ï¸ **æ³¨æ„**: ä¸è¦ä¸Šä¼ æ•æ„Ÿæ•°æ®åˆ°å…¬å…±åœ¨çº¿å·¥å…·

### 4. **ParquetViewer (Windows)** ğŸ’»
**ä¸“ç”¨å·¥å…· - è½»é‡çº§**

- **ä¸‹è½½**: https://github.com/mukunku/ParquetViewer/releases
- **ç‰¹ç‚¹**: 
  - è½»é‡çº§ Windows åº”ç”¨
  - å¿«é€ŸåŠ è½½
  - ç®€å•ç›´è§‚

**ä½¿ç”¨**: åŒå‡» .exe æ–‡ä»¶ï¼Œç„¶åæ‰“å¼€ Parquet æ–‡ä»¶

### 5. **Python è„šæœ¬** ğŸ
**æœ€çµæ´» - é€‚åˆç¼–ç¨‹ä½¿ç”¨**

#### æ–¹å¼ 1: ä½¿ç”¨é¡¹ç›®è‡ªå¸¦å·¥å…·
```bash
python view_data.py
```

#### æ–¹å¼ 2: Jupyter Notebook
```bash
pip install jupyter
jupyter notebook
```

ç„¶ååœ¨ Notebook ä¸­ï¼š
```python
import pandas as pd

df = pd.read_parquet('data/parquet/ashare_daily/**/*.parquet')
df.head(20)
```

#### æ–¹å¼ 3: äº¤äº’å¼ Python
```python
import pandas as pd
import duckdb

# æ–¹æ³• A: Pandas
df = pd.read_parquet('data/parquet/ashare_daily/**/*.parquet')
print(df)

# æ–¹æ³• B: DuckDB (æ¨èï¼Œæ›´å¿«)
con = duckdb.connect()
df = con.execute("""
    SELECT * FROM read_parquet('data/parquet/ashare_daily/**/*.parquet')
    WHERE code = '000001'
    ORDER BY date DESC
    LIMIT 10
""").df()
print(df)
```

### 6. **DuckDB CLI** ğŸ¦†
**å‘½ä»¤è¡Œå·¥å…· - é«˜æ€§èƒ½**

```bash
# å®‰è£…
pip install duckdb

# ä½¿ç”¨
python -m duckdb

# åœ¨ DuckDB æç¤ºç¬¦ä¸­
D SELECT * FROM read_parquet('data/parquet/ashare_daily/**/*.parquet') LIMIT 10;
```

### 7. **Excel / Power BI** ğŸ“Š
**å•†ä¸šåˆ†æå·¥å…·**

#### Excel Power Query
1. Excel â†’ æ•°æ® â†’ è·å–æ•°æ® â†’ ä»æ–‡ä»¶ â†’ ä» Parquet
2. é€‰æ‹© Parquet æ–‡ä»¶
3. åŠ è½½åˆ° Excel

#### Power BI
1. è·å–æ•°æ® â†’ Parquet
2. å¯¼å…¥å¹¶å¯è§†åŒ–

âš ï¸ **é™åˆ¶**: Excel æœ€å¤šåªèƒ½å¤„ç†çº¦ 100 ä¸‡è¡Œ

## ğŸ® å¿«é€Ÿå¼€å§‹ï¼šæ¨èæ–¹æ¡ˆ

### æ–¹æ¡ˆ A: è½»é‡çº§ç”¨æˆ·
1. å®‰è£… **ParquetViewer** (Windows) æˆ– **Tad** (è·¨å¹³å°)
2. ç›´æ¥æ‰“å¼€ Parquet æ–‡ä»¶æµè§ˆ

### æ–¹æ¡ˆ B: å¼€å‘è€…ç”¨æˆ·
1. ä½¿ç”¨ **VS Code** + Parquet Viewer æ‰©å±•
2. æˆ–è¿è¡Œé¡¹ç›®è‡ªå¸¦çš„ `python view_data.py`

### æ–¹æ¡ˆ C: ä¸“ä¸šåˆ†æ
1. å®‰è£… **DBeaver**
2. ä½¿ç”¨ SQL è¿›è¡Œå¤æ‚æŸ¥è¯¢å’Œåˆ†æ

## ğŸ“Š å¸¸ç”¨æŸ¥è¯¢ç¤ºä¾‹

### åœ¨ DBeaver / DuckDB ä¸­

```sql
-- æŸ¥çœ‹æŸåªè‚¡ç¥¨çš„å†å²
SELECT * FROM read_parquet('data/parquet/ashare_daily/**/*.parquet')
WHERE code = '000001'
ORDER BY date DESC;

-- æŸ¥çœ‹æœ€æ–°äº¤æ˜“æ—¥æ‰€æœ‰è‚¡ç¥¨
WITH latest_date AS (
    SELECT MAX(date) as max_date
    FROM read_parquet('data/parquet/ashare_daily/**/*.parquet')
)
SELECT * FROM read_parquet('data/parquet/ashare_daily/**/*.parquet')
WHERE date = (SELECT max_date FROM latest_date);

-- è®¡ç®—æŸè‚¡ç¥¨çš„ç§»åŠ¨å¹³å‡
SELECT 
    date,
    close,
    AVG(close) OVER (ORDER BY date ROWS BETWEEN 4 PRECEDING AND CURRENT ROW) as ma5,
    AVG(close) OVER (ORDER BY date ROWS BETWEEN 19 PRECEDING AND CURRENT ROW) as ma20
FROM read_parquet('data/parquet/ashare_daily/**/*.parquet')
WHERE code = '600519'
ORDER BY date DESC;
```

## ğŸ”§ æˆ‘çš„æ¨è

æ ¹æ®ä¸åŒéœ€æ±‚ï¼š

| éœ€æ±‚ | æ¨èå·¥å…· | åŸå›  |
|------|----------|------|
| **å¿«é€Ÿæµè§ˆ** | ParquetViewer / VS Code æ‰©å±• | ç®€å•ç›´æ¥ |
| **æ•°æ®åˆ†æ** | DBeaver + DuckDB | å¼ºå¤§çš„ SQL æ”¯æŒ |
| **ç¼–ç¨‹ä½¿ç”¨** | Python + pandas/duckdb | çµæ´»å¯æ‰©å±• |
| **å¯è§†åŒ–** | Jupyter Notebook | äº¤äº’å¼åˆ†æ |
| **å¤§æ•°æ®é›†** | DuckDB CLI | é«˜æ€§èƒ½ |

## ğŸ’¡ å°æŠ€å·§

1. **å¤§æ–‡ä»¶å¤„ç†**: ä½¿ç”¨ DuckDB è€Œä¸æ˜¯ Pandasï¼Œé€Ÿåº¦å¿« 10-100 å€
2. **è¿œç¨‹æŸ¥çœ‹**: å¯ä»¥ç”¨ Jupyter å¯åŠ¨æœåŠ¡å™¨ï¼Œæµè§ˆå™¨è®¿é—®
3. **æ•°æ®å¯¼å‡º**: åœ¨ DBeaver ä¸­å¯ä»¥å¯¼å‡ºä¸º CSV/Excel æ ¼å¼
4. **VS Code**: å¦‚æœä½ å·²ç»ç”¨ VS Code å†™ä»£ç ï¼Œç›´æ¥è£…æ‰©å±•æœ€æ–¹ä¾¿

## ğŸ“ é¡¹ç›®è‡ªå¸¦å·¥å…·

æœ¬é¡¹ç›®æä¾›äº†ä¾¿æ·çš„æŸ¥çœ‹è„šæœ¬ï¼š

```bash
# å…¨é¢æ•°æ®æµè§ˆ
python view_data.py

# ç³»ç»Ÿæµ‹è¯•ï¼ˆåŒ…å«æ•°æ®æ ·ä¾‹ï¼‰
python test_system.py
```

## ğŸ†˜ é‡åˆ°é—®é¢˜ï¼Ÿ

å¦‚æœå·¥å…·æ— æ³•æ‰“å¼€æ–‡ä»¶ï¼š
1. ç¡®è®¤ Parquet æ–‡ä»¶è·¯å¾„æ­£ç¡®
2. ç¡®è®¤æ–‡ä»¶æ²¡æœ‰æŸå
3. å°è¯•å…ˆç”¨ Python éªŒè¯ï¼š
```python
import pandas as pd
df = pd.read_parquet('ä½ çš„æ–‡ä»¶è·¯å¾„.parquet')
print(df.shape)  # åº”è¯¥æ˜¾ç¤ºè¡Œåˆ—æ•°
```

---

**å»ºè®®**: å¦‚æœä½ æ˜¯åˆæ¬¡ä½¿ç”¨ï¼Œæ¨èå…ˆç”¨ **ParquetViewer** (Windows) æˆ–é¡¹ç›®è‡ªå¸¦çš„ `python view_data.py` å¿«é€ŸæŸ¥çœ‹æ•°æ®ï¼
